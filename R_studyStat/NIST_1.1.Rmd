---
title: "NIST_1.1"
author: "Sakaguchi"
date: "2025-04-13"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
library(ggplot2)
library(gridExtra)
library(flextable)

knitr::opts_chunk$set(echo = TRUE)

```

# 1. Exploratory Data Analysis(探索的データ解析)

-   本章では探索的データ解析(EDA)で必要な仮定、原則、技術を紹介

1.  EDA Introduction(EDA導入)
2.  EDA Assumptions(仮定)
3.  EDA Techniques(技術)
4.  EDA Case Studies(ケーススタディ)

## [1.1. EDA Introduction(導入)](https://www.itl.nist.gov/div898/handbook/eda/section1/eda1.htm)

-   **Summary**

-   探索的データ解析とは?

-   どのようにして始まったか?

-   どこでどのように発生したか?

-   他のデータ分析方法とどのように異なるか?

    -   古典的、ベイズ等との比較

-   EDAとは統計的グラフと同義?

-   EDA中の統計グラフの役割は?

-   これらおよび関連する疑問に本章では解説していく

-   EDA仮定、原理、技術に必要な参照枠組みを解説

1.  What is EDA?
2.  EDA versus Classical and Bayesian
    1.  Models
    2.  Focus
    3.  Techniques
    4.  Rigor
    5.  Data Treatment
    6.  Assumptions
3.  EDA vs Summary
4.  EDA Goals
5.  The Role of Graphics
6.  An EDA/Graphics Example
7.  General Problem Categories

## [1.1.1. What is EDA?](https://www.itl.nist.gov/div898/handbook/eda/section1/eda11.htm)

-   **Approach**

-   EDAとは以下の考えを有する手法

    1.  データセットへの洞察を最大化
    2.  隠された構造を明らかに
    3.  重要変数のあぶり出し
    4.  外れ値、異常値の検出
    5.  前提となる仮定の検定
    6.  簡単なモデルの構築
    7.  最適な因子設定の決定

-   **Focus**

-   EDAはデータ分析をどう実行するかという態度・哲学

-   **Philosophy**

-   EDAと統計的グラフは近いが同じ意味ではない

    -   以下etc.

-   **History**: 割愛

-   **Techniques**

-   ほとんどのEDA技法

    -   グラフといくつかの定量技法の併用

    1.  生データをプロット

    -   ヒストグラム、バイヒストグラム、確率プロット、ラグプロット、ブロックプロット、ユーデンプロット等

    2.  簡単な統計量のプロット

    -   平均プロット、標準偏差プロット、ボックスプロット、主効果プロット等

    3.  1ページに複数プロット配置等、人間の自然なパターン認識能力を最大限に生かすようにする

## 1.1.2. 探索的データ解析は古典データ分析とどう違うか

-   **データ分析アプローチ**
-   EDAと他の統計解析手法について
    1.  古典的
    2.  EDA
    3.  ベイズ(機械学習は大体これみたい)
-   どの手法も最初と最後到達点は同様
    -   科学/エンジニアとしての疑問から
    -   科学/エンジニアとしての結論へと至る
-   過程が異なる
    -   古典的手法
        -   Problem =\> Data =\> Model =\> Analysis =\> Conclusions
    -   EDA
        -   Problem =\> Data =\> [**Analysis**]{style="color: red"} =\> Model =\> Conclusions
    -   Bayesian
        -   Problem =\> Data =\> Model =\> **Prior Distribution** =\> Analysis =\> Conclusions

- EDAでは(古典的手法と異なり)データ収集の後すぐに解析
- ベイズは分析前に事前分布を用意
  - (ベイズの解説はまたかなり後の方で)


- 現実的には、分析は複数手法の組み合わせになる

- **古典的 vs EDA**
   1. Models
   2. Focus
   3. Techniques
   4. Rigor
   5. Data Treatment
   6. Assumptions

## 1.1.2.1. [Model](https://www.itl.nist.gov/div898/handbook/eda/section1/eda121.htm)

- **古典的**
- モデルをデータに課す
  - 決定論的モデル
    - 回帰モデル
    - ANOVA
  - 確率論的モデル
    - 決定論的モデルからの誤差
    - 正規分布になる(という仮定)
      - ANOVAのF検定を使用する際の前提条件
- **EDA**
- 決定論的、確率論的モデルどちらも最初には課さない
  - データに最も適合する許容可能なモデルをデータから提案

- 1.1.2.2~1.1.2.6は説明割愛
  - そのうち表にまとめたい

## 1.1.3. [EDAと要約分析の違い](https://www.itl.nist.gov/div898/handbook/eda/section1/eda13.htm)

- **要約**
  - 過去データ(historical data)から単純な数値削減
  - 受動的
  - 過去の結果に焦点
  - いくつかの重要な統計量獲得が目的
    - 平均、標準偏差etc.
    - データセットの置き換え、あるいは要約表を追加

- **EDA**
- データの科学的/工学的背景を洞察が目標
- 能動的


## [1.1.4. EDAのゴールは?](https://www.itl.nist.gov/div898/handbook/eda/section1/eda14.htm)

- 最初の目的地
  - 分析者のデータセットに対する洞察の最大化
  - データの背後構造への洞察の最大化
- 分析者がデータセットから抽出したい下記項目
   1. 簡便かつよくフィットするモデル
   2. 外れ値のリスト
   3. 結論に関する堅牢さ
   4. パラメータの推定
   5. 上記推定の不確かさ
   6. 重要因子の順序化されたリスト
   7. ある独立した因子は統計的に重要かの結論
   8. 最適な設定とは

- **データへの洞察**
- 洞察とは
  - データの背後にある構造を明らかにすること
  - 「真の洞察」「感覚」をグラフ技法が助ける
  - 人間のパターン認識能力を使う(おおいに)

## [1.1.5. グラフの役割](https://www.itl.nist.gov/div898/handbook/eda/section1/eda15.htm)

- **定量的**
- 一連の統計的手順
  - 数値的、表形式のアウトプット
     1. 仮説検定
     2. ANOVA
     3. 点推定、区間推定
     4. 最小二乗回帰
  - 古典的分析手法の中心的存在

- **グラフ的**
  - グラフ技法と呼ばれる一連の統計ツール
     1. 散布図
     2. ヒストグラム
     3. 確率プロット
     4. 残差プロット
     5. ボックスプロット
     6. ブロックプロット

- **グラフ技術に大きく依存するEDA手法**
- EDAはグラフ技術に大きく依存
  - データセットに対する以下のような洞察得るのに有用
     1. 検定に必要な仮定
     2. モデル選定
     3. モデルの検証
     4. 推定量選択
     5. 関係識別
     6. 因子効果の決定
     7. 外れ値検出
- 統計的なグラフを使わない場合
  - データの隠された構造を洞察する機会の放棄(可能性)

## [1.1.6. EDA/グラフの例](https://www.itl.nist.gov/div898/handbook/eda/section1/eda16.htm)

- **Anscombeの例(有名な例らしい)**
- グラフがデータセットに対して洞察を与える古典的な例

### データセット(set1,2,3 and 4)と統計量


```{r 1_1_6_Anscombe_stat, echo=FALSE}
# データセットの読み込み
df <- read.table("./sampledatafiles/ANSCOMBE.DAT", skip=25)

# dfのカラム名を設定
colnames(df) <- c("X1", "Y1","X2","Y2","X3","Y3","X4","Y4")

# 統計量の項目名をベクトルで命名
items <- c("N", "Mean of X", "Mean of Y", "Intercept", "Slope", "Residual standard deviation", "Correlation")

# reg1 <- summary(lm(formula=Y1~X1, data=df))
# reg1$coefficients[1]

# 各X, Y組み合わせの統計量算出しベクトルで返す関数
calcstat <- function(x,y){
  reg <- summary(lm(formula=y~x))
  n <- length(x)
  mean_x <- mean(x)
  mean_y <- mean(y)
  intcpt <- reg$coefficients[1]
  slp <- reg$coefficients[2]
  ressd <- reg$sigma
  cor_xy <- cor(x,y)
  results <- c(n, mean_x, mean_y, intcpt, slp, ressd, cor_xy)
  return (results)
}

x1y1_rst <- calcstat(df$X1, df$Y1)
x2y2_rst <- calcstat(df$X2, df$Y2)
x3y3_rst <- calcstat(df$X3, df$Y3)
x4y4_rst <- calcstat(df$X4, df$Y4)


tbl_df <- data.frame(items,x1y1_rst,x2y2_rst,x3y3_rst,x4y4_rst)
tbl_df[,2:5] <- round(tbl_df[,2:5],3)

dtbl <- flextable(df) %>% colformat_double(., digits=2)
dtbl

stat_tbl <- flextable(tbl_df) %>% autofit() %>% colformat_double(., i=1, digits=0)

stat_tbl



```

- 4データセットとも統計量はほぼ同じで区別がつかない
  - 平均、回帰直線、線形回帰の残差標準偏差、相関係数
- 続いてグラフ化(散布図)

### グラフ技法

```{r 1_1_6_Anscombe_plot, echo=FALSE}
pltfunc <- function(x,y,title){
  plt <- ggplot(data=df, aes(x=x,y=y)) + geom_point(size=2) +
    geom_smooth(formula=y~x, method=lm) + labs(title=title, x="X", y="Y")
  return (plt)  
}

p1 <- pltfunc(df$X1, df$Y1,"exp1")
p2 <- pltfunc(df$X2, df$Y2,"exp2")
p3 <- pltfunc(df$X3, df$Y3,"exp3")
p4 <- pltfunc(df$X4, df$Y4,"exp4")

plts <- gridExtra::grid.arrange(p1,p2,p3,p4)

```

- 散布図により比較
   1. 明らかに線形モデルが適当
     - 外れ値はない
   2. グラフからは2次モデルが適していることが瞭然
   3. 1つの明らかな外れ値が存在、他は直線モデル
   4. 1つの大きく外れた実験結果の犠牲(wagging the dog)

- **EDAの重要性**

- 解析の更なる段階までモデル選択を意図的に先延ばし
- 最終的には大幅に改善されたモデルに到達
- 科学・工学的に妥当で裏付けある結論にたどり着ける

